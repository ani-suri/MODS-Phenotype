{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MODS Phenotypes: Step 2. Coallesce Grady Data to Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `import`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from random import sample\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from functools import reduce\n",
    "\n",
    "sys.path.insert(0, \"/opt/scratchspace/KLAB_SAIL/MODSPhenotypes/mods/\")\n",
    "from src.config import *\n",
    "from src.utils import *\n",
    "site_name = 'grady'\n",
    "\n",
    "# TODO: I think these are in the config files so just get them there and delete this\n",
    "input_path = Path('/opt/scratchspace/KLAB_SAIL/MODSPhenotypes/data/2023_07_29/extraction/grady/')\n",
    "years=['2014','2015','2016','2017','2018','2019','2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Coallesce `static_dfs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_schema = (\n",
    "    reduce(lambda a, b: {**a, **b}, [arrow_schema['static'][k] for k in static_keys])\n",
    "    |\n",
    "    reduce(lambda a, b: {**a, **b}, [arrow_schema['static']['times'][k] for k in times_keys])\n",
    "    )\n",
    "\n",
    "time_columns = [\n",
    "    'times_abx_order', \n",
    "    'times_culture', \n",
    "    'times_suspicion_sepsis3', \n",
    "    'times_SOFA', \n",
    "    'times_sepsis3'\n",
    "]\n",
    "\n",
    "for col in time_columns:\n",
    "    static_schema[col] = 'LIST(TIMESTAMP[NS])'\n",
    "\n",
    "arrow_static_schema = make_arrow_schema(static_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(input_path / 'static_df_YEARLY').mkdir(exist_ok=True, parents=True)\n",
    "for year in tqdm(years):\n",
    "    static_table = read_parquet_files_in_parallel(directory=input_path / 'static_df' / year,\n",
    "                                                  schema=arrow_static_schema,\n",
    "                                                  max_workers=num_cpus)\n",
    "    pq.write_table(static_table, input_path / 'static_df_YEARLY' / f\"static_df_{year}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coallesce `dynamic_dfs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_schema = (\n",
    "    arrow_schema['dynamic']['super_table'] |\n",
    "    reduce(lambda a, b: {**a, **b}, [arrow_schema['dynamic']['scores'][k] for k in scores_keys])\n",
    "    )\n",
    "\n",
    "arrow_dynamic_schema = make_arrow_schema(dynamic_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 22818/22818 [01:03<00:00, 357.79it/s]\n",
      "Reading files: 100%|██████████| 24464/24464 [01:08<00:00, 358.99it/s]\n",
      "Reading files: 100%|██████████| 26196/26196 [01:26<00:00, 302.91it/s] \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(input_path / 'dynamic_df_YEARLY').mkdir(exist_ok=True, parents=True)\n",
    "for year in tqdm(years):\n",
    "    dynamic_table = read_parquet_files_in_parallel(directory=input_path / 'dynamic_df' / year,\n",
    "                                                   schema=arrow_dynamic_schema,\n",
    "                                                   max_workers=num_cpus)\n",
    "    pq.write_table(dynamic_table, input_path / 'dynamic_df_YEARLY' / f\"dynamic_df_{year}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Re-Load `dfs` to confirm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load `static_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "__static_table = pq.read_table(\n",
    "    input_path / 'static_df_YEARLY' / '2018',\n",
    "    schema=arrow_static_schema\n",
    ")\n",
    "__static_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load `dynamic_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "__dynamic_table = pq.read_table(\n",
    "    input_path / 'dynamic_df_YEARLY' / '2018',\n",
    "    schema=arrow_dynamic_schema\n",
    ")\n",
    "__dynamic_table.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mods",
   "language": "python",
   "name": "mods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
