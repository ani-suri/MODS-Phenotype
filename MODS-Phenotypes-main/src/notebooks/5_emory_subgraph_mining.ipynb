{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODS Phenotypes: Step 5. Emory Sub-Graph Mining\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `imports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import dill as pickle\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "n_cpus = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TODO***: Instead of inserting the sys path to the local code, pip install the repo to a `mods` environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/opt/scratchspace/KLAB_SAIL/MODSPhenotypes/gSpan/\")\n",
    "import shlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gspan_mining.main import parse_args, main\n",
    "from src.gspan_mining.data_processing import process_graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name = 'emory'\n",
    "run_id = '2023_07_29'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Process the saved `pd.DataFrame()` on disk to our `.gSpan` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fp = Path(f\"/opt/scratchspace/KLAB_SAIL/MODSPhenotypes/data/{run_id}/{site_name}_sofa_scores_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path.home() / 'tmp' / 'gspan_output'\n",
    "output_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_path = data_fp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def _init_graph_worker(column, file_path, score_data):\n",
    "    \"\"\"\n",
    "    Initialize a worker to process the graph data\n",
    "    \"\"\"\n",
    "    global score_col\n",
    "    score_col = column\n",
    "    # Determine the fp based on the column name\n",
    "    global score_file_path\n",
    "    score_file_path = file_path\n",
    "    global score_df\n",
    "    score_df = score_data\n",
    "\n",
    "    \n",
    "def _append_graph_data(loc_id: str) -> None:\n",
    "    \"\"\"\n",
    "    Input is a Path located in self.dataframe_fp\n",
    "    Global variable 'score_col' is expected to be set to the column name of the score to be used\n",
    "    Parse the score_data into directed graph data (vertices and edges)\n",
    "    Appends the graph data to a text file as needed for input to gspan-mining\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loc_id: str - location id from data to be used for the graph data\n",
    "    global score_col: str - name of the score column from data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    vertices_df = score_df.loc[\n",
    "        loc_id, score_col\n",
    "    ].reset_index()  # Vertices from each score in the DF\n",
    "    if len(vertices_df) >= 2:\n",
    "        output_str = f\"t # {loc_id}\\n\"  # Start of string representation of the graph with location id\n",
    "        vertices_str = (\n",
    "            \"v\"\n",
    "            + vertices_df.to_string(header=False, index=False).replace(\"\\n\", \"\\nv \")\n",
    "            + \"\\n\"\n",
    "        )  # Determine the string representation of the graph vertices\n",
    "        output_str += (\n",
    "            vertices_str  # Add the vertices to the string representation of the graph\n",
    "        )\n",
    "        edges_df = (\n",
    "            score_df.loc[loc_id, score_col].diff(periods=1).reset_index()\n",
    "        )  # Get the differences between the scores of each vertex to get the edges\n",
    "        edges_df.rename(\n",
    "            columns={\"time_1D\": \"time_1D_to\"}, inplace=True\n",
    "        )  # rename the column name\n",
    "        edges_df[\"time_1D_from\"] = (\n",
    "            edges_df[\"time_1D_to\"] - 1\n",
    "        )  # each timestep edge represents one hour\n",
    "        edges_df[score_col] = (\n",
    "            edges_df[score_col].replace(np.nan, 0).astype(int)\n",
    "        )  # replace NaNs with 0\n",
    "        edges_df = edges_df[\n",
    "            [\"time_1D_from\", \"time_1D_to\", score_col]\n",
    "        ]  # order the columns\n",
    "        edges_df = edges_df.iloc[\n",
    "            1:, :\n",
    "        ]  # drop the last row because it does not exist in graph\n",
    "        output_str += (\n",
    "            \"e\"\n",
    "            + edges_df.to_string(header=False, index=False).replace(\"\\n\", \"\\ne \")\n",
    "            + \"\\n\"\n",
    "        )\n",
    "        # End the graph and output string\n",
    "        output_str = (\n",
    "            output_str.replace(\"  \", \" \").replace(\"e0\", \"e 0\").replace(\"v0\", \"v 0\")\n",
    "        )\n",
    "        with open(score_file_path, \"a\") as fi:\n",
    "            fi.write(output_str)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "excluded_cols=[\"time_1D\"]\n",
    "if Path(df_path).suffix == \".parquet\":\n",
    "    score_data = pd.read_parquet(Path(df_path))\n",
    "elif Path(df_path).suffix == \".csv\":\n",
    "    score_data = pd.read_csv(Path(df_path).suffix)\n",
    "else:\n",
    "    raise ValueError(\"Input file must be a .parquet or .csv file\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "columns = [col for col in score_data.columns if col not in excluded_cols]\n",
    "output_dir = Path(output_dir)\n",
    "loc_ids = score_data.index.get_level_values(0).unique()\n",
    "\n",
    "fps = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fps = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for column in tqdm(columns):\n",
    "    file_path = output_dir / f\"{column}.gSpan\"\n",
    "    # Multiprocessing hack to fix scope issues is to use a global variable pointing to variable\n",
    "    # TODO: Check if I can fix this using a class scope or alternative method\n",
    "    # Create an empty .gSpan file to append results to, if it does not exist\n",
    "    # TODO: ask user if they want to delete the file before unlinking\n",
    "    if file_path.exists():\n",
    "        file_path.unlink()\n",
    "    # Create the filepath folder if it does not exist\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # touch the output text file to create it\n",
    "    with open(file_path, \"w\") as _:\n",
    "        pass\n",
    "    # Multiprocessing on the dataframe to append graph data to the .gSpan file\n",
    "    pool = Pool(\n",
    "        initializer=_init_graph_worker,\n",
    "        initargs=(column, file_path, score_data),\n",
    "        processes=n_cpus,\n",
    "    )\n",
    "    for _ in tqdm(\n",
    "        # TODO: imap is slower than asynchronous? See if we can make it asynch without breaking gSpan\n",
    "        pool.imap(func=_append_graph_data, iterable=loc_ids),\n",
    "        total=len(loc_ids),\n",
    "    ):\n",
    "        pass\n",
    "    fps.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2371c91a89e344d89be937f509410203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6495c820d5734625b164e31e27530516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f6767249ac41e4a9a03f8477861af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b225a57c0bb84a34901c68c4dbcf2db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c02b82c78642d6a5b9f6d329bea69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0d9c2905f149edb732544fed51da1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64726f6f791c416ab85237a76cb00aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 10s, sys: 6min 7s, total: 11min 17s\n",
      "Wall time: 11min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: benchmark the wall clock time on this call\n",
    "file_paths = process_graph_data(data_fp, output_dir, n_cpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Frequent Subgraph Mining (FSM) with gSpan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Data to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our support using the ratio of 20 for 20k patients from literature\n",
    "support = int((20/20_000)*55799)\n",
    "min_subgraph_len = 3\n",
    "max_subgraph_len = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arg_string = f\"-fp '{file_paths[0].parent}' -s {support} -l {min_subgraph_len} -u {max_subgraph_len}\"\n",
    "args = parse_args(shlex.split(arg_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(gspan_fp=PosixPath('/home/gmatlin/tmp/gspan_output'), support=55, lower=3, upper=6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110846a9b56a46a99fc3b5da9fc719c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running `gSpan` package on each `.gSpan` file:: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read:\t8.41 s\n",
      "Mine:\t51.81999999999999 s\n",
      "Total:\t60.23 s\n",
      "Read:\t8.16 s\n",
      "Mine:\t49.370000000000005 s\n",
      "Total:\t57.53 s\n",
      "Read:\t8.92 s\n",
      "Mine:\t51.629999999999995 s\n",
      "Total:\t60.55 s\n",
      "Read:\t9.94 s\n",
      "Mine:\t46.18 s\n",
      "Total:\t56.12 s\n",
      "Read:\t10.5 s\n",
      "Mine:\t46.78 s\n",
      "Total:\t57.28 s\n",
      "Read:\t3.81 s\n",
      "Mine:\t46.82 s\n",
      "Total:\t50.63 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753fb95ecf484f7ca5d8415652ecfdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building a report from each column result:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONCAT DATA\n",
      "CPU times: user 34min 58s, sys: 6.85 s, total: 35min 5s\n",
      "Wall time: 35min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: SPEED UP REPORTING IN GRAPH MINING\n",
    "# TODO: ADD PRINT STATEMENTS TO INDICATE HOW FAR ALONG\n",
    "# TODO: TQDM FOR THE REPORT LOOPS\n",
    "# TODO: PANDAS ALTERNATIVE FOR THE REPORTING SLOG??\n",
    "\n",
    "graph_miner = main(args) # WARNING: TAKES A FEW HOURS (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save `graph_miner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/home/gmatlin/tmp/{site_name}_{run_id}_graph_miner.pkl\", \"wb\") as dill_file:\n",
    "    pickle.dump(graph_miner, dill_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load `graph_miner`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(f\"/home/gmatlin/tmp/{site_name}_{run_id}_graph_miner.pkl\", \"rb\") as dill_file:\n",
    "    graph_miner = pickle.load(dill_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mods",
   "language": "python",
   "name": "mods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
