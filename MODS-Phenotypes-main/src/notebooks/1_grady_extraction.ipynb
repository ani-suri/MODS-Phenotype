{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MODS Phenotypes - Step 1. Extract Data for Grady"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import warnings\n",
    "from random import sample\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from functools import reduce\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/opt/scratchspace/KLAB_SAIL/MODSPhenotypes/mods\")\n",
    "from src.config import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name = 'grady'\n",
    "sample_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (\n",
    "    project_path / \"data\" / str(run_id) / \"extraction\" / site_name\n",
    ")\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = project_config[site_name][\"keys\"][\"patient_key\"]\n",
    "service_id = project_config[site_name][\"keys\"][\"service_key\"]\n",
    "record_dt = project_config[site_name][\"keys\"][\"record_dt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this shouldnt be needed make it go away\n",
    "scores_keys = project_config[site_name][\"scores\"]\n",
    "static_keys = project_config[site_name][\"static\"]\n",
    "dynamic_keys = project_config[site_name][\"dynamic\"]\n",
    "times_keys = project_config[site_name][\"times\"]\n",
    "datetimes_keys = project_config[site_name][\"datetimes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `extraction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(pickle_path):\n",
    "    encounter_pickle, filename_without_ext = load_encounter_pickle(pickle_path)\n",
    "    extract_dynamic_df(encounter_pickle, pickle_path, filename_without_ext)\n",
    "    extract_static_df(encounter_pickle, pickle_path, filename_without_ext)\n",
    "    extract_perCSN_dfs(encounter_pickle, pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `extract_dynamic_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dynamic_df(encounter_pickle, pickle_path, filename_without_ext):\n",
    "    super_df = get_super_df(encounter_pickle, pickle_path, filename_without_ext)\n",
    "    \n",
    "    scores_df = get_scores_df(encounter_pickle, pickle_path)\n",
    "    \n",
    "    dynamic_df = pd.merge(left=super_df, right=scores_df,\n",
    "                          how='left', \n",
    "                        left_on=[record_dt], \n",
    "                        right_on=[record_dt],\n",
    "                       suffixes=('_super','_dynamic'))\n",
    "\n",
    "    dynamic_table = pa.Table.from_pandas(dynamic_df, preserve_index=False)\n",
    "    \n",
    "    output_folder = output_path / \"dynamic_df\" / str(pickle_path.parent.stem)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    pq.write_table(dynamic_table,\n",
    "                   output_folder / f\"{pickle_path.stem}.parquet\",\n",
    "                   # TODO: Get from config\n",
    "                   version='2.6', compression='snappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `get_super_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_super_df(encounter_pickle, pickle_path, filename_without_ext, cols_to_drop=None):\n",
    "    # Get SuperTable\n",
    "    try:\n",
    "        super_df = encounter_pickle['super_table']\n",
    "    except KeyError as e:\n",
    "        print(f\"(get_super_df) KeyError: 'super_table' not in {str(pickle_path.stem)}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        super_df[patient_id] = str(encounter_pickle['pt_id'])\n",
    "    except KeyError as e:\n",
    "        try:\n",
    "            super_df[patient_id] = str(encounter_pickle['pat_id'])\n",
    "        except KeyError as e:\n",
    "            print(f\"(get_super_df) KeyError: neither 'pt_id' or 'pat_id' was found in {str(pickle_path.stem)}\")\n",
    "            return\n",
    "\n",
    "    # Drop columns\n",
    "    if cols_to_drop:\n",
    "        for col in cols_to_drop:\n",
    "            try:\n",
    "                super_df.drop(labels=col, axis=1, inplace=True)\n",
    "            except KeyError:\n",
    "                print(f\"(get_super_df) KeyError in {str(pickle_path.stem)} when dropping '{col}' column\")\n",
    "                pass  # may not be in all encounters\n",
    "    \n",
    "    # Assign CSN to SuperTable\n",
    "    try:\n",
    "        str(encounter_pickle[service_id])\n",
    "    except KeyError as e:\n",
    "        super_df[service_id] = filename_without_ext  # Use the filename without extension here\n",
    "    else:\n",
    "        super_df[service_id] = str(encounter_pickle[service_id])\n",
    "\n",
    "    super_df.reset_index(inplace=True, drop=False)\n",
    "    super_df.rename(columns={\"index\": record_dt}, inplace=True)\n",
    "    \n",
    "    for key in (set(pandas_schema['dynamic']['super_table'].keys()) - set(super_df.columns)):\n",
    "        super_df[key] = None\n",
    "        super_df[key] = super_df[key].astype(pandas_schema['dynamic']['super_table'][key])\n",
    "\n",
    "    try:\n",
    "        super_df = super_df[pandas_schema['dynamic']['super_table'].keys()]\n",
    "    except KeyError as e:\n",
    "        print(f\"(get_super_df) KeyError in {str(encounter_pickle[service_id])} when using keys from pandas_schema: {e}\")\n",
    "\n",
    "    super_schema = {}\n",
    "    for col in super_df.columns:\n",
    "        try:\n",
    "            super_schema[col] = pandas_schema['dynamic']['super_table'][col]\n",
    "        except KeyError as e:\n",
    "            print(f\"(get_super_df) KeyError with {col} in {str(pickle_path.stem)} when building super_schema\")\n",
    "\n",
    "    try:\n",
    "        super_df = super_df.astype(super_schema)\n",
    "    except TypeError as e:\n",
    "        print(f\"TypeError in {str(pickle_path.stem)}: {e}\")\n",
    "        # Identify and print problematic column and its unique values\n",
    "        for col, dtype in super_schema.items():\n",
    "            try:\n",
    "                super_df[col].astype(dtype)\n",
    "            except Exception as inner_e:\n",
    "                print(f\"Column {col} with values {super_df[col].unique()} caused error: {inner_e}\")\n",
    "\n",
    "    return super_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `get_scores_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_df(encounter_pickle, pickle_path):\n",
    "    # SOFA scores\n",
    "    sofa_df = encounter_pickle['sofa_scores']\n",
    "    sofa_rename_map = {\n",
    "        'hourly_total': 'SOFA_hourly_total',\n",
    "        'delta_24h': 'SOFA_delta_24h',\n",
    "        'hourly_total_mod': 'SOFA_hourly_total_mod',\n",
    "        'delta_24h_mod': 'SOFA_delta_24h_mod'\n",
    "    }\n",
    "    sofa_df.rename(columns=sofa_rename_map, inplace=True)\n",
    "\n",
    "    # Check for 'sirs_scores' in encounter_pickle\n",
    "    if 'sirs_scores' in encounter_pickle:\n",
    "        sirs_df = encounter_pickle['sirs_scores']\n",
    "        sirs_rename_map = {\n",
    "            'hourly_total': 'SIRS_hourly_total',\n",
    "            'delta_24h': 'SIRS_delta_24h'\n",
    "        }\n",
    "        sirs_df.rename(columns=sirs_rename_map, inplace=True)\n",
    "    else:\n",
    "        # Create an empty DataFrame with the same index as sofa_df\n",
    "        sirs_df = pd.DataFrame(index=sofa_df.index)\n",
    "    \n",
    "    # Merging\n",
    "    scores_df = pd.merge(left=sofa_df, right=sirs_df,\n",
    "                         how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    # Type casting\n",
    "    scores_schema = {}\n",
    "    for key in scores_keys:\n",
    "        # Check if key exists in scores_df\n",
    "        if key in scores_df.columns:\n",
    "            scores_schema = scores_schema | pandas_schema['dynamic']['scores'][key]\n",
    "\n",
    "    # Check the existence of the column before trying to set its dtype\n",
    "    for col, dtype in scores_schema.items():\n",
    "        if col in scores_df.columns:\n",
    "            try:\n",
    "                scores_df[col] = scores_df[col].astype(dtype)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {str(pickle_path.stem)} for column {col}: {e}\")\n",
    "\n",
    "    scores_df.reset_index(inplace=True, drop=False)\n",
    "    scores_df.rename(columns={\"index\": record_dt}, inplace=True)\n",
    "    \n",
    "    return scores_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `extract_static_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_static_df(encounter_pickle, pickle_path, filename_without_ext):\n",
    "\n",
    "    static_df = get_static_df(encounter_pickle)\n",
    "    times_df = get_times_df(encounter_pickle)\n",
    "    \n",
    "    static_df = pd.concat([static_df, times_df], axis=1)\n",
    "\n",
    "    static_schema = {}\n",
    "    for key in static_keys:\n",
    "        static_schema = static_schema | pandas_schema['static'][key]\n",
    "    for key in times_keys:\n",
    "        static_schema = static_schema | pandas_schema['static']['times'][key]\n",
    "\n",
    "    # Filter the schema to only include columns present in the dataframe\n",
    "    filtered_schema = {col: dtype for col, dtype in static_schema.items() if col in static_df.columns}\n",
    "    try:\n",
    "        static_df = static_df.astype(filtered_schema)\n",
    "    except Exception as e:  # Catching a broader exception in case there are other issues beyond KeyError\n",
    "        print(f\"(extract_static_df) Error for {str(pickle_path.stem)} when doing .astype(filtered_schema): {e}\")\n",
    "\n",
    "    static_df.rename(columns={\n",
    "        't_suspicion': 'times_suspicion_sepsis3',\n",
    "        't_SOFA':'times_SOFA',\n",
    "        't_sepsis3':'times_sepsis3',\n",
    "        't_abx':'times_abx_order',\n",
    "        't_clt':'times_culture'\n",
    "        },\n",
    "                     inplace=True)\n",
    "    # dealing with `ed_wait_time`\n",
    "    if type(static_df.loc[0,'ed_wait_time']) is pd.Timedelta:\n",
    "        static_df.loc[0,'ed_wait_time'] = float(static_df['ed_wait_time'][0].seconds/60)\n",
    "\n",
    "    if pd.isnull(static_df.loc[0,'ed_wait_time']):\n",
    "        static_df.loc[0,'ed_wait_time'] = 0.0\n",
    "        static_df.loc[0,'ed_wait_time'] = float('nan')            \n",
    "\n",
    "    static_table = pa.Table.from_pandas(static_df, preserve_index=False)\n",
    "\n",
    "    output_folder = output_path / \"static_df\" / str(pickle_path.parent.stem)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pq.write_table(static_table,\n",
    "                   output_folder / f\"{pickle_path.stem}.parquet\",\n",
    "                   # TODO: Get from config\n",
    "                   version='2.6', compression='snappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `get_static_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_static_df(encounter_pickle):\n",
    "    static_dict = reduce(lambda a, b: {**a, **b}, [encounter_pickle[k] for k in static_keys])\n",
    "\n",
    "    # Dealing with ed_wait_time issues\n",
    "    if 'ed_wait_time' not in static_dict.keys():\n",
    "        static_dict['ed_wait_time'] = float('nan')\n",
    "    \n",
    "    static_df = pd.DataFrame(pd.Series(static_dict)).T\n",
    "    return static_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `get_times_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_times_df(encounter_pickle):\n",
    "    times_data = [\n",
    "        denoise_times(encounter_pickle['sep3_time'].t_suspicion),\n",
    "        denoise_times(encounter_pickle['t_suspicion'].t_clt),\n",
    "        denoise_times(encounter_pickle['t_suspicion'].t_abx),\n",
    "        denoise_times(encounter_pickle['sep3_time'].t_SOFA),\n",
    "        denoise_times(encounter_pickle['sep3_time'].t_sepsis3)\n",
    "    ]\n",
    "\n",
    "    times_df = pd.DataFrame([times_data], columns = [\n",
    "        't_suspicion',\n",
    "        't_clt',\n",
    "        't_abx',\n",
    "        't_SOFA',\n",
    "        't_sepsis3'\n",
    "        ])\n",
    "    \n",
    "    for n in times_df.columns:\n",
    "        try:\n",
    "            if times_df[n][0].size == 0:\n",
    "                times_df[n][0] = [pd.NaT]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `extract_perCSN_dfs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_perCSN_dfs(encounter_pickle, pickle_path):\n",
    "    extract_beds_df(encounter_pickle, pickle_path)\n",
    "    extract_diagnosis_df(encounter_pickle, pickle_path)\n",
    "    extract_procedures_df(encounter_pickle, pickle_path)\n",
    "    extract_cultures_df(encounter_pickle, pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_beds_df(encounter_pickle, pickle_path):\n",
    "    beds_df = encounter_pickle[\"beds_PerCSN\"]\n",
    "    beds_df.reset_index(inplace=True)\n",
    "    beds_df.rename(columns={'index':'csn'}, inplace=True)\n",
    "\n",
    "    beds_table = pa.Table.from_pandas(beds_df, preserve_index=False)\n",
    "\n",
    "    output_folder = output_path / \"beds_df\" / str(pickle_path.parent.stem)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pq.write_table(beds_table,\n",
    "                   output_folder / f\"{pickle_path.stem}.parquet\",\n",
    "                   version='2.6', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_diagnosis_df(encounter_pickle, pickle_path):\n",
    "    diagnosis_df = encounter_pickle[\"diagnosis_PerCSN\"]\n",
    "    diagnosis_df.reset_index(inplace=True)\n",
    "    diagnosis_df.rename(columns={'index':'csn'}, inplace=True)\n",
    "\n",
    "    diagnosis_table = pa.Table.from_pandas(diagnosis_df, preserve_index=False)\n",
    "\n",
    "    output_folder = output_path / \"diagnosis_df\" / str(pickle_path.parent.stem)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pq.write_table(diagnosis_table,\n",
    "                   output_folder / f\"{pickle_path.stem}.parquet\",\n",
    "                   version='2.6', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_procedures_df(encounter_pickle, pickle_path):\n",
    "    procedures_df = encounter_pickle[\"procedures_PerCSN\"]\n",
    "    procedures_df.reset_index(inplace=True)\n",
    "    procedures_df.rename(columns={'index':'csn'}, inplace=True)\n",
    "\n",
    "    procedures_table = pa.Table.from_pandas(procedures_df, preserve_index=False)\n",
    "\n",
    "    output_folder = output_path / \"procedures_df\" / str(pickle_path.parent.stem)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pq.write_table(procedures_table,\n",
    "                   output_folder / f\"{pickle_path.stem}.parquet\",\n",
    "                   version='2.6', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cultures_df(encounter_pickle, pickle_path):\n",
    "    cultures_df = encounter_pickle[\"cultures_PerCSN\"]\n",
    "    cultures_df.reset_index(inplace=True)\n",
    "    cultures_df.rename(columns={'index':'csn'}, inplace=True)\n",
    "\n",
    "    cultures_table = pa.Table.from_pandas(cultures_df, preserve_index=False)\n",
    "\n",
    "    output_folder = output_path / \"cultures_df\" / str(pickle_path.parent.stem)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pq.write_table(cultures_table,\n",
    "                   output_folder / f\"{pickle_path.stem}.parquet\",\n",
    "                   version='2.6', compression='snappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `main()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    file_path=config[site_name]['filepaths']['encounter_pickles']\n",
    "    years=config[site_name]['years']\n",
    "    sample_rate=config['parameters']['sample_rate']\n",
    "    num_cpus=config['parameters']['num_cpus']\n",
    "    pickle_paths = find_pickle_paths(file_path=file_path,\n",
    "                                     years=years,\n",
    "                                     sample_rate=sample_rate)\n",
    "    with Pool(processes=num_cpus) as pool:\n",
    "        max_ = len(pickle_paths)\n",
    "        with tqdm(total=max_) as pbar:\n",
    "            for _ in pool.imap_unordered(func=extraction, iterable=pickle_paths):\n",
    "                pbar.update()\n",
    "\n",
    "main(project_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load `dynamic_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pat_id</th>\n",
       "      <th>csn</th>\n",
       "      <th>charttime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>daily_weight_kg</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>sbp_line</th>\n",
       "      <th>dbp_line</th>\n",
       "      <th>map_line</th>\n",
       "      <th>sbp_cuff</th>\n",
       "      <th>...</th>\n",
       "      <th>SOFA_hourly_total</th>\n",
       "      <th>SOFA_delta_24h</th>\n",
       "      <th>SOFA_hourly_total_mod</th>\n",
       "      <th>SOFA_delta_24h_mod</th>\n",
       "      <th>SIRS_resp</th>\n",
       "      <th>SIRS_cardio</th>\n",
       "      <th>SIRS_temp</th>\n",
       "      <th>SIRS_wbc</th>\n",
       "      <th>SIRS_hourly_total</th>\n",
       "      <th>SIRS_delta_24h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z2128263</td>\n",
       "      <td>1021009657</td>\n",
       "      <td>2018-02-26 12:06:00</td>\n",
       "      <td>100.6</td>\n",
       "      <td>49.9</td>\n",
       "      <td>165.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z2128263</td>\n",
       "      <td>1021009657</td>\n",
       "      <td>2018-02-26 13:06:00</td>\n",
       "      <td>100.6</td>\n",
       "      <td>49.9</td>\n",
       "      <td>165.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z2128263</td>\n",
       "      <td>1021009657</td>\n",
       "      <td>2018-02-26 14:06:00</td>\n",
       "      <td>103.1</td>\n",
       "      <td>49.9</td>\n",
       "      <td>165.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z2128263</td>\n",
       "      <td>1021009657</td>\n",
       "      <td>2018-02-26 15:06:00</td>\n",
       "      <td>101.5</td>\n",
       "      <td>49.9</td>\n",
       "      <td>165.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z2128263</td>\n",
       "      <td>1021009657</td>\n",
       "      <td>2018-02-26 16:06:00</td>\n",
       "      <td>101.5</td>\n",
       "      <td>49.9</td>\n",
       "      <td>165.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pat_id         csn           charttime  temperature  daily_weight_kg  \\\n",
       "0  Z2128263  1021009657 2018-02-26 12:06:00        100.6             49.9   \n",
       "1  Z2128263  1021009657 2018-02-26 13:06:00        100.6             49.9   \n",
       "2  Z2128263  1021009657 2018-02-26 14:06:00        103.1             49.9   \n",
       "3  Z2128263  1021009657 2018-02-26 15:06:00        101.5             49.9   \n",
       "4  Z2128263  1021009657 2018-02-26 16:06:00        101.5             49.9   \n",
       "\n",
       "   height_cm  sbp_line  dbp_line  map_line  sbp_cuff  ...  SOFA_hourly_total  \\\n",
       "0      165.1       NaN       NaN       NaN     144.5  ...                1.0   \n",
       "1      165.1       NaN       NaN       NaN     156.5  ...                1.0   \n",
       "2      165.1       NaN       NaN       NaN     165.0  ...                1.0   \n",
       "3      165.1       NaN       NaN       NaN     172.0  ...                2.0   \n",
       "4      165.1       NaN       NaN       NaN     172.0  ...                2.0   \n",
       "\n",
       "   SOFA_delta_24h  SOFA_hourly_total_mod  SOFA_delta_24h_mod  SIRS_resp  \\\n",
       "0             1.0                    1.0                 1.0        0.0   \n",
       "1             1.0                    1.0                 1.0        1.0   \n",
       "2             1.0                    1.0                 1.0        1.0   \n",
       "3             2.0                    2.0                 2.0        0.0   \n",
       "4             2.0                    2.0                 2.0        0.0   \n",
       "\n",
       "   SIRS_cardio  SIRS_temp  SIRS_wbc  SIRS_hourly_total  SIRS_delta_24h  \n",
       "0          1.0        1.0       1.0                3.0             3.0  \n",
       "1          1.0        1.0       1.0                4.0             4.0  \n",
       "2          1.0        1.0       1.0                4.0             4.0  \n",
       "3          1.0        1.0       1.0                3.0             4.0  \n",
       "4          1.0        1.0       1.0                3.0             4.0  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.8 ms, sys: 31.2 ms, total: 94 ms\n",
      "Wall time: 305 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dynamic_schema = (\n",
    "    arrow_schema['dynamic']['super_table'] |\n",
    "    reduce(lambda a, b: {**a, **b}, [arrow_schema['dynamic']['scores'][k] for k in scores_keys])\n",
    "    )\n",
    "\n",
    "arrow_dynamic_schema = make_arrow_schema(dynamic_schema)\n",
    "\n",
    "dynamic_table = pq.read_table(\n",
    "    str(output_path/'dynamic_df'/'2018'/'1021009657.parquet'),\n",
    "    use_pandas_metadata=True,\n",
    "    schema=arrow_dynamic_schema\n",
    ")\n",
    "dynamic_df = dynamic_table.to_pandas()\n",
    "display(dynamic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load `static_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reduce' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "static_schema = (\n",
    "    reduce(lambda a, b: {**a, **b}, [arrow_schema['static'][k] for k in static_keys])\n",
    "    |\n",
    "    reduce(lambda a, b: {**a, **b}, [arrow_schema['static']['times'][k] for k in times_keys])\n",
    "    )\n",
    "static_schema['times_abx_order'] = 'LIST(TIMESTAMP[NS])'\n",
    "static_schema['times_culture'] = 'LIST(TIMESTAMP[NS])'\n",
    "static_schema['times_suspicion_sepsis3'] = 'LIST(TIMESTAMP[NS])'\n",
    "static_schema['times_SOFA'] = 'LIST(TIMESTAMP[NS])'\n",
    "static_schema['times_sepsis3'] = 'LIST(TIMESTAMP[NS])'\n",
    "\n",
    "arrow_static_schema = make_arrow_schema(static_schema)\n",
    "\n",
    "static_table = pq.read_table(\n",
    "    str(output_path/'static_df'/'2018'/'1021009657.parquet'),\n",
    "    use_pandas_metadata=True,\n",
    "    schema=arrow_static_schema\n",
    ")\n",
    "\n",
    "static_df = static_table.to_pandas()\n",
    "\n",
    "display(static_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load `beds_PerCSN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_schema['perCSN']['beds_PerCSN']['csn']='STRING'\n",
    "arrow_schema['perCSN']['beds_PerCSN']['pat_id']='STRING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csn</th>\n",
       "      <th>pat_id</th>\n",
       "      <th>bed_location_start</th>\n",
       "      <th>bed_location_end</th>\n",
       "      <th>bed_unit</th>\n",
       "      <th>bed_room</th>\n",
       "      <th>bed_id</th>\n",
       "      <th>bed_label</th>\n",
       "      <th>hospital_service</th>\n",
       "      <th>accomodation_code</th>\n",
       "      <th>accomodation_description</th>\n",
       "      <th>icu</th>\n",
       "      <th>imc</th>\n",
       "      <th>ed</th>\n",
       "      <th>procedure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021009657</td>\n",
       "      <td>Z2128263</td>\n",
       "      <td>2018-02-26 12:10:00</td>\n",
       "      <td>2018-02-26 14:36:00</td>\n",
       "      <td>GHS EMERGENCY</td>\n",
       "      <td>Z2-20</td>\n",
       "      <td>7053</td>\n",
       "      <td>Z2-20</td>\n",
       "      <td>Emergency Medicine (Non-admitting)</td>\n",
       "      <td>10016</td>\n",
       "      <td>Intermediate Care</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021009657</td>\n",
       "      <td>Z2128263</td>\n",
       "      <td>2018-02-26 14:36:00</td>\n",
       "      <td>2018-02-27 03:47:00</td>\n",
       "      <td>GHS EMERGENCY</td>\n",
       "      <td>Z3-47</td>\n",
       "      <td>7199</td>\n",
       "      <td>Z3-47</td>\n",
       "      <td>Emergency Medicine (Non-admitting)</td>\n",
       "      <td>10016</td>\n",
       "      <td>Intermediate Care</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021009657</td>\n",
       "      <td>Z2128263</td>\n",
       "      <td>2018-02-27 03:47:00</td>\n",
       "      <td>2018-02-27 04:05:00</td>\n",
       "      <td>GHS EMERGENCY</td>\n",
       "      <td>OTF1</td>\n",
       "      <td>1001</td>\n",
       "      <td>OTF</td>\n",
       "      <td>Emergency Medicine (Non-admitting)</td>\n",
       "      <td>10016</td>\n",
       "      <td>Intermediate Care</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021009657</td>\n",
       "      <td>Z2128263</td>\n",
       "      <td>2018-02-27 04:05:00</td>\n",
       "      <td>2018-02-28 21:28:00</td>\n",
       "      <td>GHS 5KOF</td>\n",
       "      <td>5KOF</td>\n",
       "      <td>7405</td>\n",
       "      <td>5K09</td>\n",
       "      <td>Emergency Medicine (Non-admitting)</td>\n",
       "      <td>10016</td>\n",
       "      <td>Intermediate Care</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          csn    pat_id  bed_location_start    bed_location_end  \\\n",
       "0  1021009657  Z2128263 2018-02-26 12:10:00 2018-02-26 14:36:00   \n",
       "1  1021009657  Z2128263 2018-02-26 14:36:00 2018-02-27 03:47:00   \n",
       "2  1021009657  Z2128263 2018-02-27 03:47:00 2018-02-27 04:05:00   \n",
       "3  1021009657  Z2128263 2018-02-27 04:05:00 2018-02-28 21:28:00   \n",
       "\n",
       "        bed_unit bed_room bed_id bed_label  \\\n",
       "0  GHS EMERGENCY    Z2-20   7053     Z2-20   \n",
       "1  GHS EMERGENCY    Z3-47   7199     Z3-47   \n",
       "2  GHS EMERGENCY     OTF1   1001       OTF   \n",
       "3       GHS 5KOF     5KOF   7405      5K09   \n",
       "\n",
       "                     hospital_service accomodation_code  \\\n",
       "0  Emergency Medicine (Non-admitting)             10016   \n",
       "1  Emergency Medicine (Non-admitting)             10016   \n",
       "2  Emergency Medicine (Non-admitting)             10016   \n",
       "3  Emergency Medicine (Non-admitting)             10016   \n",
       "\n",
       "  accomodation_description  icu  imc   ed  procedure  \n",
       "0        Intermediate Care  0.0  0.0  1.0        0.0  \n",
       "1        Intermediate Care  0.0  0.0  1.0        0.0  \n",
       "2        Intermediate Care  0.0  0.0  1.0        0.0  \n",
       "3        Intermediate Care  0.0  0.0  0.0        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 ms, sys: 11.8 ms, total: 26.1 ms\n",
      "Wall time: 74.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arrow_beds_schema = make_arrow_schema(arrow_schema['perCSN']['beds_PerCSN'])\n",
    "\n",
    "beds_table = pq.read_table(\n",
    "    str(output_path/'beds_df'/'2018'/'1021009657.parquet'),\n",
    "    use_pandas_metadata=True,\n",
    "    schema=arrow_beds_schema\n",
    ")\n",
    "\n",
    "beds_df = beds_table.to_pandas()\n",
    "\n",
    "display(beds_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load `cultures_PerCSN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csn</th>\n",
       "      <th>pat_id</th>\n",
       "      <th>proc_code</th>\n",
       "      <th>proc_desc</th>\n",
       "      <th>component_id</th>\n",
       "      <th>component</th>\n",
       "      <th>loinc_code</th>\n",
       "      <th>specimen_collect_time</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_id</th>\n",
       "      <th>result_id</th>\n",
       "      <th>lab_result_time</th>\n",
       "      <th>result_status</th>\n",
       "      <th>lab_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021009657</td>\n",
       "      <td>Z2128263</td>\n",
       "      <td>LAB239</td>\n",
       "      <td>URINE CULTURE</td>\n",
       "      <td>123040764</td>\n",
       "      <td>Culture</td>\n",
       "      <td>11475-1</td>\n",
       "      <td>2018-02-27 03:01:00</td>\n",
       "      <td>2018-02-26 19:14:00</td>\n",
       "      <td>139732207</td>\n",
       "      <td>P389850</td>\n",
       "      <td>2018-02-28 10:51:00</td>\n",
       "      <td>Preliminary</td>\n",
       "      <td>10-100,000 CFU/ML Escherichia coli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021009657</td>\n",
       "      <td>Z2128263</td>\n",
       "      <td>LAB239</td>\n",
       "      <td>URINE CULTURE</td>\n",
       "      <td>123040764</td>\n",
       "      <td>Culture</td>\n",
       "      <td>11475-1</td>\n",
       "      <td>2018-02-27 03:01:00</td>\n",
       "      <td>2018-02-26 19:14:00</td>\n",
       "      <td>139732207</td>\n",
       "      <td>P392144</td>\n",
       "      <td>2018-02-28 13:29:00</td>\n",
       "      <td>Preliminary</td>\n",
       "      <td>10-100,000 CFU/ML Escherichia coli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021009657</td>\n",
       "      <td>Z2128263</td>\n",
       "      <td>LAB239</td>\n",
       "      <td>URINE CULTURE</td>\n",
       "      <td>123040764</td>\n",
       "      <td>Culture</td>\n",
       "      <td>11475-1</td>\n",
       "      <td>2018-02-27 03:01:00</td>\n",
       "      <td>2018-02-26 19:14:00</td>\n",
       "      <td>139732207</td>\n",
       "      <td>P375048</td>\n",
       "      <td>2018-03-01 10:15:00</td>\n",
       "      <td>Verified</td>\n",
       "      <td>10-100,000 CFU/ML Escherichia coli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021009657</td>\n",
       "      <td>Z2128263</td>\n",
       "      <td>LAB462</td>\n",
       "      <td>BLOOD CULTURE</td>\n",
       "      <td>123040764</td>\n",
       "      <td>Culture</td>\n",
       "      <td>11475-1</td>\n",
       "      <td>2018-02-26 20:26:00</td>\n",
       "      <td>2018-02-26 19:35:00</td>\n",
       "      <td>139732211</td>\n",
       "      <td>P384181</td>\n",
       "      <td>2018-02-27 21:00:00</td>\n",
       "      <td>Preliminary</td>\n",
       "      <td>Escherichia coli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021009657</td>\n",
       "      <td>Z2128263</td>\n",
       "      <td>LAB462</td>\n",
       "      <td>BLOOD CULTURE</td>\n",
       "      <td>123040764</td>\n",
       "      <td>Culture</td>\n",
       "      <td>11475-1</td>\n",
       "      <td>2018-02-26 20:26:00</td>\n",
       "      <td>2018-02-26 19:35:00</td>\n",
       "      <td>139732211</td>\n",
       "      <td>P384181</td>\n",
       "      <td>2018-02-27 21:00:00</td>\n",
       "      <td>Preliminary</td>\n",
       "      <td>Critical Results</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          csn    pat_id proc_code      proc_desc component_id component  \\\n",
       "0  1021009657  Z2128263    LAB239  URINE CULTURE    123040764   Culture   \n",
       "1  1021009657  Z2128263    LAB239  URINE CULTURE    123040764   Culture   \n",
       "2  1021009657  Z2128263    LAB239  URINE CULTURE    123040764   Culture   \n",
       "3  1021009657  Z2128263    LAB462  BLOOD CULTURE    123040764   Culture   \n",
       "4  1021009657  Z2128263    LAB462  BLOOD CULTURE    123040764   Culture   \n",
       "\n",
       "  loinc_code specimen_collect_time          order_time   order_id result_id  \\\n",
       "0    11475-1   2018-02-27 03:01:00 2018-02-26 19:14:00  139732207   P389850   \n",
       "1    11475-1   2018-02-27 03:01:00 2018-02-26 19:14:00  139732207   P392144   \n",
       "2    11475-1   2018-02-27 03:01:00 2018-02-26 19:14:00  139732207   P375048   \n",
       "3    11475-1   2018-02-26 20:26:00 2018-02-26 19:35:00  139732211   P384181   \n",
       "4    11475-1   2018-02-26 20:26:00 2018-02-26 19:35:00  139732211   P384181   \n",
       "\n",
       "      lab_result_time result_status                          lab_result  \n",
       "0 2018-02-28 10:51:00   Preliminary  10-100,000 CFU/ML Escherichia coli  \n",
       "1 2018-02-28 13:29:00   Preliminary  10-100,000 CFU/ML Escherichia coli  \n",
       "2 2018-03-01 10:15:00      Verified  10-100,000 CFU/ML Escherichia coli  \n",
       "3 2018-02-27 21:00:00   Preliminary                    Escherichia coli  \n",
       "4 2018-02-27 21:00:00   Preliminary                    Critical Results  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 ms, sys: 5.43 ms, total: 23.9 ms\n",
      "Wall time: 17.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arrow_schema['perCSN']['cultures_PerCSN']['csn']='STRING'\n",
    "arrow_schema['perCSN']['cultures_PerCSN']['pat_id']='STRING'\n",
    "arrow_schema['perCSN']['cultures_PerCSN']['proc_code']='STRING'\n",
    "arrow_schema['perCSN']['cultures_PerCSN']['component_id']='STRING'\n",
    "arrow_schema['perCSN']['cultures_PerCSN']['order_id']='STRING'\n",
    "arrow_schema['perCSN']['cultures_PerCSN']['result_id']='STRING'\n",
    "arrow_cultures_schema = make_arrow_schema(arrow_schema['perCSN']['cultures_PerCSN'])\n",
    "\n",
    "cultures_table = pq.read_table(\n",
    "    str(output_path/'cultures_df'/'2018'/'1021009657.parquet'),\n",
    "    use_pandas_metadata=True,\n",
    "    schema=arrow_cultures_schema\n",
    ")\n",
    "\n",
    "cultures_df = cultures_table.to_pandas()\n",
    "\n",
    "display(cultures_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load `procedures_PerCSN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csn</th>\n",
       "      <th>pat_id</th>\n",
       "      <th>surgery_date</th>\n",
       "      <th>in_or_dttm</th>\n",
       "      <th>procedure_start_dttm</th>\n",
       "      <th>procedure_comp_dttm</th>\n",
       "      <th>out_or_dttm</th>\n",
       "      <th>or_procedure_id</th>\n",
       "      <th>primary_procedure_nm</th>\n",
       "      <th>cpt_code</th>\n",
       "      <th>service_nm</th>\n",
       "      <th>primary_physician_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021729214</td>\n",
       "      <td>Z2202010</td>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>2018-03-02 07:56:00</td>\n",
       "      <td>2018-03-02 08:24:00</td>\n",
       "      <td>2018-03-02 10:42:00</td>\n",
       "      <td>2018-03-02 10:57:00</td>\n",
       "      <td>None</td>\n",
       "      <td>TANGENTIAL EXCISION OF BURN WOUND</td>\n",
       "      <td>None</td>\n",
       "      <td>Burns</td>\n",
       "      <td>WILLIAMS, RACHAEL Y.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021729214</td>\n",
       "      <td>Z2202010</td>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>2018-03-16 07:46:00</td>\n",
       "      <td>2018-03-16 08:13:00</td>\n",
       "      <td>2018-03-16 08:56:00</td>\n",
       "      <td>2018-03-16 09:06:00</td>\n",
       "      <td>None</td>\n",
       "      <td>AMPUTATION, TOE; METATARSOPHALANGEAL JOINT</td>\n",
       "      <td>28820</td>\n",
       "      <td>Burns</td>\n",
       "      <td>WILLIAMS, RACHAEL Y.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021729214</td>\n",
       "      <td>Z2202010</td>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>2018-04-12 12:59:00</td>\n",
       "      <td>2018-04-12 13:46:00</td>\n",
       "      <td>2018-04-12 18:31:00</td>\n",
       "      <td>2018-04-12 18:31:00</td>\n",
       "      <td>None</td>\n",
       "      <td>TANGENTIAL EXCISION OF BURN WOUND</td>\n",
       "      <td>None</td>\n",
       "      <td>Burns</td>\n",
       "      <td>INGRAM, WALTER L.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          csn    pat_id surgery_date          in_or_dttm procedure_start_dttm  \\\n",
       "0  1021729214  Z2202010   2018-03-02 2018-03-02 07:56:00  2018-03-02 08:24:00   \n",
       "1  1021729214  Z2202010   2018-03-16 2018-03-16 07:46:00  2018-03-16 08:13:00   \n",
       "2  1021729214  Z2202010   2018-04-12 2018-04-12 12:59:00  2018-04-12 13:46:00   \n",
       "\n",
       "  procedure_comp_dttm         out_or_dttm or_procedure_id  \\\n",
       "0 2018-03-02 10:42:00 2018-03-02 10:57:00            None   \n",
       "1 2018-03-16 08:56:00 2018-03-16 09:06:00            None   \n",
       "2 2018-04-12 18:31:00 2018-04-12 18:31:00            None   \n",
       "\n",
       "                         primary_procedure_nm cpt_code service_nm  \\\n",
       "0           TANGENTIAL EXCISION OF BURN WOUND     None      Burns   \n",
       "1  AMPUTATION, TOE; METATARSOPHALANGEAL JOINT    28820      Burns   \n",
       "2           TANGENTIAL EXCISION OF BURN WOUND     None      Burns   \n",
       "\n",
       "   primary_physician_nm  \n",
       "0  WILLIAMS, RACHAEL Y.  \n",
       "1  WILLIAMS, RACHAEL Y.  \n",
       "2     INGRAM, WALTER L.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 ms, sys: 7.46 ms, total: 21.1 ms\n",
      "Wall time: 17.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arrow_schema['perCSN']['procedures_PerCSN']['csn']='STRING'\n",
    "arrow_schema['perCSN']['procedures_PerCSN']['pat_id']='STRING'\n",
    "arrow_procedures_schema = make_arrow_schema(arrow_schema['perCSN']['procedures_PerCSN'])\n",
    "\n",
    "procedures_table = pq.read_table(\n",
    "    str(output_path/'procedures_df'/'2018'/'1021729214.parquet'),\n",
    "    use_pandas_metadata=True,\n",
    "    schema=arrow_procedures_schema\n",
    ")\n",
    "\n",
    "procedures_df = procedures_table.to_pandas()\n",
    "\n",
    "display(procedures_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load `diagnosis_PerCSN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csn</th>\n",
       "      <th>pat_id</th>\n",
       "      <th>dx_line</th>\n",
       "      <th>dx_icd_scope</th>\n",
       "      <th>dx_code_icd9</th>\n",
       "      <th>dx_code_icd10</th>\n",
       "      <th>dx_source</th>\n",
       "      <th>dx_time_date</th>\n",
       "      <th>dx_code</th>\n",
       "      <th>dx_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021735826</td>\n",
       "      <td>Z2172494</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O365930</td>\n",
       "      <td>ADMISSION DX (CODED)</td>\n",
       "      <td>2018-02-08 06:21:40</td>\n",
       "      <td>O36.5930</td>\n",
       "      <td>Maternal care for other known or suspected poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021735826</td>\n",
       "      <td>Z2172494</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>O365930</td>\n",
       "      <td>FINAL DIAGNOSES</td>\n",
       "      <td>2018-02-08 06:21:00</td>\n",
       "      <td>O36.5930</td>\n",
       "      <td>Maternal care for other known or suspected poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021735826</td>\n",
       "      <td>Z2172494</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>R030</td>\n",
       "      <td>FINAL DIAGNOSES</td>\n",
       "      <td>2018-02-08 06:21:00</td>\n",
       "      <td>R03.0</td>\n",
       "      <td>Elevated blood-pressure reading, without diagn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021735826</td>\n",
       "      <td>Z2172494</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>O9989</td>\n",
       "      <td>FINAL DIAGNOSES</td>\n",
       "      <td>2018-02-08 06:21:00</td>\n",
       "      <td>O99.89</td>\n",
       "      <td>Other specified diseases and conditions compli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021735826</td>\n",
       "      <td>Z2172494</td>\n",
       "      <td>4</td>\n",
       "      <td>Exempt from POA reporting</td>\n",
       "      <td>None</td>\n",
       "      <td>Z370</td>\n",
       "      <td>FINAL DIAGNOSES</td>\n",
       "      <td>2018-02-08 06:21:00</td>\n",
       "      <td>Z37.0</td>\n",
       "      <td>Single live birth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          csn    pat_id dx_line               dx_icd_scope dx_code_icd9  \\\n",
       "0  1021735826  Z2172494       1                       None         None   \n",
       "1  1021735826  Z2172494       1                        Yes         None   \n",
       "2  1021735826  Z2172494       2                        Yes         None   \n",
       "3  1021735826  Z2172494       3                        Yes         None   \n",
       "4  1021735826  Z2172494       4  Exempt from POA reporting         None   \n",
       "\n",
       "  dx_code_icd10             dx_source        dx_time_date   dx_code  \\\n",
       "0       O365930  ADMISSION DX (CODED) 2018-02-08 06:21:40  O36.5930   \n",
       "1       O365930       FINAL DIAGNOSES 2018-02-08 06:21:00  O36.5930   \n",
       "2          R030       FINAL DIAGNOSES 2018-02-08 06:21:00     R03.0   \n",
       "3         O9989       FINAL DIAGNOSES 2018-02-08 06:21:00    O99.89   \n",
       "4          Z370       FINAL DIAGNOSES 2018-02-08 06:21:00     Z37.0   \n",
       "\n",
       "                                             dx_name  \n",
       "0  Maternal care for other known or suspected poo...  \n",
       "1  Maternal care for other known or suspected poo...  \n",
       "2  Elevated blood-pressure reading, without diagn...  \n",
       "3  Other specified diseases and conditions compli...  \n",
       "4                                  Single live birth  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 3.77 ms, total: 19.8 ms\n",
      "Wall time: 47.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arrow_schema['perCSN']['diagnosis_PerCSN']['csn']='STRING'\n",
    "arrow_schema['perCSN']['diagnosis_PerCSN']['pat_id']='STRING'\n",
    "arrow_diagnosis_schema = make_arrow_schema(arrow_schema['perCSN']['diagnosis_PerCSN'])\n",
    "\n",
    "diagnosis_table = pq.read_table(\n",
    "    str(output_path/'diagnosis_df'/'2018'/'1021735826.parquet'),\n",
    "    use_pandas_metadata=True,\n",
    "    schema=arrow_diagnosis_schema\n",
    ")\n",
    "\n",
    "diagnosis_df = diagnosis_table.to_pandas()\n",
    "\n",
    "display(diagnosis_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mods",
   "language": "python",
   "name": "mods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
